{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Reinforcement learning ",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P74amGMjlozO"
      },
      "source": [
        "# Installing Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h670qMozM728",
        "outputId": "0b2c965a-4660-4428-b948-1a4207707ff7"
      },
      "source": [
        "!pip install stable-baselines[mpi]\r\n",
        "!pip install tensorflow==1.15.4\r\n",
        "!pip install gym==0.15.3\r\n",
        "!pip install pyfolio\r\n",
        "!pip install stockstats"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stable-baselines[mpi] in /usr/local/lib/python3.6/dist-packages (2.10.1)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (0.15.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.18.5)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (1.1.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (4.1.2.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (0.17.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (3.2.2)\n",
            "Requirement already satisfied: mpi4py; extra == \"mpi\" in /usr/local/lib/python3.6/dist-packages (from stable-baselines[mpi]) (3.0.3)\n",
            "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (1.15.0)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (7.0.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (0.2.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines[mpi]) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines[mpi]) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines[mpi]) (0.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]) (0.16.0)\n",
            "Requirement already satisfied: tensorflow==1.15.4 in /usr/local/lib/python3.6/dist-packages (1.15.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.33.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (0.35.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (0.2.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (0.2.2)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.18.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.15.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.4) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.4) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.4) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4) (3.4.0)\n",
            "Requirement already satisfied: gym==0.15.3 in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.15.3) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym==0.15.3) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym==0.15.3) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym==0.15.3) (1.15.0)\n",
            "Requirement already satisfied: cloudpickle~=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym==0.15.3) (1.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym==0.15.3) (0.16.0)\n",
            "Requirement already satisfied: pyfolio in /usr/local/lib/python3.6/dist-packages (0.9.2)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.6/dist-packages (from pyfolio) (5.5.0)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from pyfolio) (1.1.4)\n",
            "Requirement already satisfied: scikit-learn>=0.16.1 in /usr/local/lib/python3.6/dist-packages (from pyfolio) (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from pyfolio) (3.2.2)\n",
            "Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from pyfolio) (0.5.5)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.6/dist-packages (from pyfolio) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from pyfolio) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from pyfolio) (1.4.1)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from pyfolio) (0.11.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=3.2.3->pyfolio) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=3.2.3->pyfolio) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=3.2.3->pyfolio) (4.3.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=3.2.3->pyfolio) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=3.2.3->pyfolio) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=3.2.3->pyfolio) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=3.2.3->pyfolio) (50.3.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=3.2.3->pyfolio) (4.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.1->pyfolio) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16.1->pyfolio) (0.17.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->pyfolio) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->pyfolio) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->pyfolio) (1.3.1)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.6/dist-packages (from empyrical>=0.5.0->pyfolio) (0.9.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=3.2.3->pyfolio) (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=3.2.3->pyfolio) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=3.2.3->pyfolio) (0.6.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (4.2.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2020.11.8)\n",
            "Requirement already satisfied: stockstats in /usr/local/lib/python3.6/dist-packages (0.3.2)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from stockstats) (1.18.5)\n",
            "Requirement already satisfied: int-date>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from stockstats) (0.1.8)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from stockstats) (1.1.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from int-date>=0.1.7->stockstats) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.4.2 in /usr/local/lib/python3.6/dist-packages (from int-date>=0.1.7->stockstats) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.1->stockstats) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skTwBqKvluUZ"
      },
      "source": [
        "# Naming Locations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEIoDECuRnPC"
      },
      "source": [
        "import pathlib\r\n",
        "\r\n",
        "#import finrl\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import datetime\r\n",
        "import os\r\n",
        "TRAINING_DATA_FILE = \"dow_30_2009_2020.csv\"\r\n",
        "\r\n",
        "now = datetime.datetime.now()\r\n",
        "TRAINED_MODEL_DIR = f\"trained_models/{now}\"\r\n",
        "os.makedirs(TRAINED_MODEL_DIR)\r\n",
        "TURBULENCE_DATA = \"dow30_turbulence_index.csv\"\r\n",
        "\r\n",
        "TESTING_DATA_FILE = \"test.csv\""
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ijdotcql0_n"
      },
      "source": [
        "# Importing modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XTOmNGkNd7L"
      },
      "source": [
        "from stable_baselines import SAC\r\n",
        "from stable_baselines import PPO2\r\n",
        "from stable_baselines import A2C\r\n",
        "from stable_baselines import DDPG\r\n",
        "from stable_baselines import TD3\r\n",
        "from stable_baselines.ddpg.policies import DDPGPolicy\r\n",
        "from stable_baselines.common.policies import MlpPolicy\r\n",
        "from stable_baselines.common.vec_env import DummyVecEnv\r\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo6qXF7SRSZb"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from stockstats import StockDataFrame as Sdf\r\n",
        "\r\n",
        "def load_dataset(*, file_name: str) -> pd.DataFrame:\r\n",
        "    \"\"\"\r\n",
        "    load csv dataset from path\r\n",
        "    :return: (df) pandas dataframe\r\n",
        "    \"\"\"\r\n",
        "    #_data = pd.read_csv(f\"{DATASET_DIR}/{file_name}\")\r\n",
        "    _data = pd.read_csv(file_name)\r\n",
        "    return _data\r\n",
        "\r\n",
        "def data_split(df,start,end):\r\n",
        "    \"\"\"\r\n",
        "    split the dataset into training or testing using date\r\n",
        "    :param data: (df) pandas dataframe, start, end\r\n",
        "    :return: (df) pandas dataframe\r\n",
        "    \"\"\"\r\n",
        "    data = df[(df.datadate >= start) & (df.datadate < end)]\r\n",
        "    data=data.sort_values(['datadate','tic'],ignore_index=True)\r\n",
        "    #data  = data[final_columns]\r\n",
        "    data.index = data.datadate.factorize()[0]\r\n",
        "    return data\r\n",
        "\r\n",
        "def calcualte_price(df):\r\n",
        "    \"\"\"\r\n",
        "    calcualte adjusted close price, open-high-low price and volume\r\n",
        "    :param data: (df) pandas dataframe\r\n",
        "    :return: (df) pandas dataframe\r\n",
        "    \"\"\"\r\n",
        "    data = df.copy()\r\n",
        "    data = data[['datadate', 'tic', 'prccd', 'ajexdi', 'prcod', 'prchd', 'prcld', 'cshtrd']]\r\n",
        "    data['ajexdi'] = data['ajexdi'].apply(lambda x: 1 if x == 0 else x)\r\n",
        "\r\n",
        "    data['adjcp'] = data['prccd'] / data['ajexdi']\r\n",
        "    data['open'] = data['prcod'] / data['ajexdi']\r\n",
        "    data['high'] = data['prchd'] / data['ajexdi']\r\n",
        "    data['low'] = data['prcld'] / data['ajexdi']\r\n",
        "    data['volume'] = data['cshtrd']\r\n",
        "\r\n",
        "    data = data[['datadate', 'tic', 'adjcp', 'open', 'high', 'low', 'volume']]\r\n",
        "    data = data.sort_values(['tic', 'datadate'], ignore_index=True)\r\n",
        "    return data\r\n",
        "\r\n",
        "def add_technical_indicator(df):\r\n",
        "    \"\"\"\r\n",
        "    calcualte technical indicators\r\n",
        "    use stockstats package to add technical inidactors\r\n",
        "    :param data: (df) pandas dataframe\r\n",
        "    :return: (df) pandas dataframe\r\n",
        "    \"\"\"\r\n",
        "    stock = Sdf.retype(df.copy())\r\n",
        "\r\n",
        "    stock['close'] = stock['adjcp']\r\n",
        "    unique_ticker = stock.tic.unique()\r\n",
        "\r\n",
        "    macd = pd.DataFrame()\r\n",
        "    rsi = pd.DataFrame()\r\n",
        "    cci = pd.DataFrame()\r\n",
        "    dx = pd.DataFrame()\r\n",
        "\r\n",
        "    #temp = stock[stock.tic == unique_ticker[0]]['macd']\r\n",
        "    for i in range(len(unique_ticker)):\r\n",
        "        ## macd\r\n",
        "        temp_macd = stock[stock.tic == unique_ticker[i]]['macd']\r\n",
        "        temp_macd = pd.DataFrame(temp_macd)\r\n",
        "        macd = macd.append(temp_macd, ignore_index=True)\r\n",
        "        ## rsi\r\n",
        "        temp_rsi = stock[stock.tic == unique_ticker[i]]['rsi_30']\r\n",
        "        temp_rsi = pd.DataFrame(temp_rsi)\r\n",
        "        rsi = rsi.append(temp_rsi, ignore_index=True)\r\n",
        "        ## cci\r\n",
        "        temp_cci = stock[stock.tic == unique_ticker[i]]['cci_30']\r\n",
        "        temp_cci = pd.DataFrame(temp_cci)\r\n",
        "        cci = cci.append(temp_cci, ignore_index=True)\r\n",
        "        ## adx\r\n",
        "        temp_dx = stock[stock.tic == unique_ticker[i]]['dx_30']\r\n",
        "        temp_dx = pd.DataFrame(temp_dx)\r\n",
        "        dx = dx.append(temp_dx, ignore_index=True)\r\n",
        "\r\n",
        "\r\n",
        "    df['macd'] = macd\r\n",
        "    df['rsi'] = rsi\r\n",
        "    df['cci'] = cci\r\n",
        "    df['adx'] = dx\r\n",
        "\r\n",
        "    return df\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def preprocess_data():\r\n",
        "    \"\"\"data preprocessing pipeline\"\"\"\r\n",
        "\r\n",
        "    df = load_dataset(file_name=TRAINING_DATA_FILE)\r\n",
        "    # get data after 2009\r\n",
        "    df = df[df.datadate>=20090000]\r\n",
        "    # calcualte adjusted price\r\n",
        "    df_preprocess = calcualte_price(df)\r\n",
        "    # add technical indicators using stockstats\r\n",
        "    df_final=add_technical_indicator(df_preprocess)\r\n",
        "    # fill the missing values at the beginning\r\n",
        "    df_final.fillna(method='bfill',inplace=True)\r\n",
        "    return df_final\r\n",
        "\r\n",
        "def add_turbulence(df):\r\n",
        "    \"\"\"\r\n",
        "    add turbulence index from a precalcualted dataframe\r\n",
        "    :param data: (df) pandas dataframe\r\n",
        "    :return: (df) pandas dataframe\r\n",
        "    \"\"\"\r\n",
        "    turbulence_index = calcualte_turbulence(df)\r\n",
        "    df = df.merge(turbulence_index, on='datadate')\r\n",
        "    df = df.sort_values(['datadate','tic']).reset_index(drop=True)\r\n",
        "    return df\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def calcualte_turbulence(df):\r\n",
        "    \"\"\"calculate turbulence index based on dow 30\"\"\"\r\n",
        "    # can add other market assets\r\n",
        "    \r\n",
        "    df_price_pivot=df.pivot(index='datadate', columns='tic', values='adjcp')\r\n",
        "    unique_date = df.datadate.unique()\r\n",
        "    # start after a year\r\n",
        "    start = 252\r\n",
        "    turbulence_index = [0]*start\r\n",
        "    #turbulence_index = [0]\r\n",
        "    count=0\r\n",
        "    for i in range(start,len(unique_date)):\r\n",
        "        current_price = df_price_pivot[df_price_pivot.index == unique_date[i]]\r\n",
        "        hist_price = df_price_pivot[[n in unique_date[0:i] for n in df_price_pivot.index ]]\r\n",
        "        cov_temp = hist_price.cov()\r\n",
        "        current_temp=(current_price - np.mean(hist_price,axis=0))\r\n",
        "        temp = current_temp.values.dot(np.linalg.inv(cov_temp)).dot(current_temp.values.T)\r\n",
        "        if temp>0:\r\n",
        "            count+=1\r\n",
        "            if count>2:\r\n",
        "                turbulence_temp = temp[0][0]\r\n",
        "            else:\r\n",
        "                #avoid large outlier because of the calculation just begins\r\n",
        "                turbulence_temp=0\r\n",
        "        else:\r\n",
        "            turbulence_temp=0\r\n",
        "        turbulence_index.append(turbulence_temp)\r\n",
        "    \r\n",
        "    \r\n",
        "    turbulence_index = pd.DataFrame({'datadate':df_price_pivot.index,\r\n",
        "                                     'turbulence':turbulence_index})\r\n",
        "    return turbulence_index"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKBQKzjjPTyO"
      },
      "source": [
        "# common library\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import time\r\n",
        "import gym\r\n",
        "\r\n",
        "# RL models from stable-baselines\r\n",
        "from stable_baselines import GAIL, SAC\r\n",
        "from stable_baselines import ACER\r\n",
        "from stable_baselines import PPO2\r\n",
        "from stable_baselines import A2C\r\n",
        "from stable_baselines import DDPG\r\n",
        "from stable_baselines import TD3\r\n",
        "\r\n",
        "from stable_baselines.ddpg.policies import DDPGPolicy\r\n",
        "from stable_baselines.common.policies import MlpPolicy, MlpLstmPolicy, MlpLnLstmPolicy\r\n",
        "from stable_baselines.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise, AdaptiveParamNoiseSpec\r\n",
        "from stable_baselines.common.vec_env import DummyVecEnv\r\n",
        "\r\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "665_1EO9jKfN"
      },
      "source": [
        "  \r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from gym.utils import seeding\r\n",
        "import gym\r\n",
        "from gym import spaces\r\n",
        "import matplotlib\r\n",
        "matplotlib.use('Agg')\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pickle\r\n",
        "\r\n",
        "# shares normalization factor\r\n",
        "# 100 shares per trade\r\n",
        "HMAX_NORMALIZE = 100\r\n",
        "# initial amount of money we have in our account\r\n",
        "INITIAL_ACCOUNT_BALANCE=1000000\r\n",
        "# total number of stocks in our portfolio\r\n",
        "STOCK_DIM = 30\r\n",
        "# transaction fee: 1/1000 reasonable percentage\r\n",
        "TRANSACTION_FEE_PERCENT = 0.001\r\n",
        "\r\n",
        "# turbulence index: 90-150 reasonable threshold\r\n",
        "#TURBULENCE_THRESHOLD = 140\r\n",
        "REWARD_SCALING = 1e-4\r\n",
        "\r\n",
        "class StockEnvTrade(gym.Env):\r\n",
        "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\r\n",
        "    metadata = {'render.modes': ['human']}\r\n",
        "\r\n",
        "    def __init__(self, df,day = 0,turbulence_threshold=140\r\n",
        "                 ,initial=True, previous_state=[], model_name='', iteration=''):\r\n",
        "        #super(StockEnv, self).__init__()\r\n",
        "        #money = 10 , scope = 1\r\n",
        "        self.day = day\r\n",
        "        self.df = df\r\n",
        "        self.initial = initial\r\n",
        "        self.previous_state = previous_state\r\n",
        "        # action_space normalization and shape is STOCK_DIM\r\n",
        "        self.action_space = spaces.Box(low = -1, high = 1,shape = (STOCK_DIM,)) \r\n",
        "        # Shape = 181: [Current Balance]+[prices 1-30]+[owned shares 1-30] \r\n",
        "        # +[macd 1-30]+ [rsi 1-30] + [cci 1-30] + [adx 1-30]\r\n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape = (181,))\r\n",
        "        # load data from a pandas dataframe\r\n",
        "        self.data = self.df.loc[self.day,:]\r\n",
        "        self.terminal = False     \r\n",
        "        self.turbulence_threshold = turbulence_threshold\r\n",
        "        # initalize state\r\n",
        "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\r\n",
        "                      self.data.adjcp.values.tolist() + \\\r\n",
        "                      [0]*STOCK_DIM + \\\r\n",
        "                      self.data.macd.values.tolist() + \\\r\n",
        "                      self.data.rsi.values.tolist() + \\\r\n",
        "                      self.data.cci.values.tolist() + \\\r\n",
        "                      self.data.adx.values.tolist()\r\n",
        "        # initialize reward\r\n",
        "        self.reward = 0\r\n",
        "        self.turbulence = 0\r\n",
        "        self.cost = 0\r\n",
        "        self.trades = 0\r\n",
        "        # memorize all the total balance change\r\n",
        "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\r\n",
        "        self.rewards_memory = []\r\n",
        "        #self.reset()\r\n",
        "        self._seed()\r\n",
        "        self.model_name=model_name        \r\n",
        "        self.iteration=iteration\r\n",
        "\r\n",
        "\r\n",
        "    def _sell_stock(self, index, action):\r\n",
        "        # perform sell action based on the sign of the action\r\n",
        "        if self.turbulence<self.turbulence_threshold:\r\n",
        "            if self.state[index+STOCK_DIM+1] > 0:\r\n",
        "                #update balance\r\n",
        "                self.state[0] += \\\r\n",
        "                self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\r\n",
        "                 (1- TRANSACTION_FEE_PERCENT)\r\n",
        "                \r\n",
        "                self.state[index+STOCK_DIM+1] -= min(abs(action), self.state[index+STOCK_DIM+1])\r\n",
        "                self.cost +=self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\r\n",
        "                 TRANSACTION_FEE_PERCENT\r\n",
        "                self.trades+=1\r\n",
        "            else:\r\n",
        "                pass\r\n",
        "        else:\r\n",
        "            # if turbulence goes over threshold, just clear out all positions \r\n",
        "            if self.state[index+STOCK_DIM+1] > 0:\r\n",
        "                #update balance\r\n",
        "                self.state[0] += self.state[index+1]*self.state[index+STOCK_DIM+1]* \\\r\n",
        "                              (1- TRANSACTION_FEE_PERCENT)\r\n",
        "                self.state[index+STOCK_DIM+1] =0\r\n",
        "                self.cost += self.state[index+1]*self.state[index+STOCK_DIM+1]* \\\r\n",
        "                              TRANSACTION_FEE_PERCENT\r\n",
        "                self.trades+=1\r\n",
        "            else:\r\n",
        "                pass\r\n",
        "    \r\n",
        "    def _buy_stock(self, index, action):\r\n",
        "        # perform buy action based on the sign of the action\r\n",
        "        if self.turbulence< self.turbulence_threshold:\r\n",
        "            available_amount = self.state[0] // self.state[index+1]\r\n",
        "            # print('available_amount:{}'.format(available_amount))\r\n",
        "            \r\n",
        "            #update balance\r\n",
        "            self.state[0] -= self.state[index+1]*min(available_amount, action)* \\\r\n",
        "                              (1+ TRANSACTION_FEE_PERCENT)\r\n",
        "\r\n",
        "            self.state[index+STOCK_DIM+1] += min(available_amount, action)\r\n",
        "            \r\n",
        "            self.cost+=self.state[index+1]*min(available_amount, action)* \\\r\n",
        "                              TRANSACTION_FEE_PERCENT\r\n",
        "            self.trades+=1\r\n",
        "        else:\r\n",
        "            # if turbulence goes over threshold, just stop buying\r\n",
        "            pass\r\n",
        "        \r\n",
        "    def step(self, actions):\r\n",
        "        # print(self.day)\r\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\r\n",
        "        # print(actions)\r\n",
        "\r\n",
        "        if self.terminal:\r\n",
        "            plt.plot(self.asset_memory,'r')\r\n",
        "            plt.savefig('results/account_value_trade_{}_{}.png'.format(self.model_name, self.iteration))\r\n",
        "            plt.close()\r\n",
        "            df_total_value = pd.DataFrame(self.asset_memory)\r\n",
        "            df_total_value.to_csv('results/account_value_trade_{}_{}.csv'.format(self.model_name, self.iteration))\r\n",
        "            end_total_asset = self.state[0]+ \\\r\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\r\n",
        "            print(\"previous_total_asset:{}\".format(self.asset_memory[0]))           \r\n",
        "\r\n",
        "            print(\"end_total_asset:{}\".format(end_total_asset))\r\n",
        "            print(\"total_reward:{}\".format(self.state[0]+sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))- self.asset_memory[0] ))\r\n",
        "            print(\"total_cost: \", self.cost)\r\n",
        "            print(\"total trades: \", self.trades)\r\n",
        "\r\n",
        "            df_total_value.columns = ['account_value']\r\n",
        "            df_total_value['daily_return']=df_total_value.pct_change(1)\r\n",
        "            sharpe = (4**0.5)*df_total_value['daily_return'].mean()/ \\\r\n",
        "                  df_total_value['daily_return'].std()\r\n",
        "            print(\"Sharpe: \",sharpe)\r\n",
        "            \r\n",
        "            df_rewards = pd.DataFrame(self.rewards_memory)\r\n",
        "            df_rewards.to_csv('results/account_rewards_trade_{}_{}.csv'.format(self.model_name, self.iteration))\r\n",
        "            \r\n",
        "            # print('total asset: {}'.format(self.state[0]+ sum(np.array(self.state[1:29])*np.array(self.state[29:]))))\r\n",
        "            #with open('obs.pkl', 'wb') as f:  \r\n",
        "            #    pickle.dump(self.state, f)\r\n",
        "            \r\n",
        "            return self.state, self.reward, self.terminal,{}\r\n",
        "\r\n",
        "        else:\r\n",
        "            # print(np.array(self.state[1:29]))\r\n",
        "\r\n",
        "            actions = actions * HMAX_NORMALIZE\r\n",
        "            #actions = (actions.astype(int))\r\n",
        "            if self.turbulence>=self.turbulence_threshold:\r\n",
        "                actions=np.array([-HMAX_NORMALIZE]*STOCK_DIM)\r\n",
        "                \r\n",
        "            begin_total_asset = self.state[0]+ \\\r\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\r\n",
        "            #print(\"begin_total_asset:{}\".format(begin_total_asset))\r\n",
        "            \r\n",
        "            argsort_actions = np.argsort(actions)\r\n",
        "            \r\n",
        "            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\r\n",
        "            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\r\n",
        "\r\n",
        "            for index in sell_index:\r\n",
        "                # print('take sell action'.format(actions[index]))\r\n",
        "                self._sell_stock(index, actions[index])\r\n",
        "\r\n",
        "            for index in buy_index:\r\n",
        "                # print('take buy action: {}'.format(actions[index]))\r\n",
        "                self._buy_stock(index, actions[index])\r\n",
        "\r\n",
        "            self.day += 1\r\n",
        "            self.data = self.df.loc[self.day,:]         \r\n",
        "            self.turbulence = self.data['turbulence'].values[0]\r\n",
        "            #print(self.turbulence)\r\n",
        "            #load next state\r\n",
        "            # print(\"stock_shares:{}\".format(self.state[29:]))\r\n",
        "            self.state =  [self.state[0]] + \\\r\n",
        "                    self.data.adjcp.values.tolist() + \\\r\n",
        "                    list(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]) + \\\r\n",
        "                    self.data.macd.values.tolist() + \\\r\n",
        "                    self.data.rsi.values.tolist() + \\\r\n",
        "                    self.data.cci.values.tolist() + \\\r\n",
        "                    self.data.adx.values.tolist()\r\n",
        "            \r\n",
        "            end_total_asset = self.state[0]+ \\\r\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\r\n",
        "            self.asset_memory.append(end_total_asset)\r\n",
        "            #print(\"end_total_asset:{}\".format(end_total_asset))\r\n",
        "            \r\n",
        "            self.reward = end_total_asset - begin_total_asset            \r\n",
        "            # print(\"step_reward:{}\".format(self.reward))\r\n",
        "            self.rewards_memory.append(self.reward)\r\n",
        "            \r\n",
        "            self.reward = self.reward*REWARD_SCALING\r\n",
        "\r\n",
        "\r\n",
        "        return self.state, self.reward, self.terminal, {}\r\n",
        "\r\n",
        "    def reset(self):  \r\n",
        "        if self.initial:\r\n",
        "            self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\r\n",
        "            self.day = 0\r\n",
        "            self.data = self.df.loc[self.day,:]\r\n",
        "            self.turbulence = 0\r\n",
        "            self.cost = 0\r\n",
        "            self.trades = 0\r\n",
        "            self.terminal = False \r\n",
        "            #self.iteration=self.iteration\r\n",
        "            self.rewards_memory = []\r\n",
        "            #initiate state\r\n",
        "            self.state = [INITIAL_ACCOUNT_BALANCE] + \\\r\n",
        "                          self.data.adjcp.values.tolist() + \\\r\n",
        "                          [0]*STOCK_DIM + \\\r\n",
        "                          self.data.macd.values.tolist() + \\\r\n",
        "                          self.data.rsi.values.tolist()  + \\\r\n",
        "                          self.data.cci.values.tolist()  + \\\r\n",
        "                          self.data.adx.values.tolist() \r\n",
        "        else:\r\n",
        "            previous_total_asset = self.previous_state[0]+ \\\r\n",
        "            sum(np.array(self.previous_state[1:(STOCK_DIM+1)])*np.array(self.previous_state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\r\n",
        "            self.asset_memory = [previous_total_asset]\r\n",
        "            #self.asset_memory = [self.previous_state[0]]\r\n",
        "            self.day = 0\r\n",
        "            self.data = self.df.loc[self.day,:]\r\n",
        "            self.turbulence = 0\r\n",
        "            self.cost = 0\r\n",
        "            self.trades = 0\r\n",
        "            self.terminal = False \r\n",
        "            #self.iteration=iteration\r\n",
        "            self.rewards_memory = []\r\n",
        "            #initiate state\r\n",
        "            #self.previous_state[(STOCK_DIM+1):(STOCK_DIM*2+1)]\r\n",
        "            #[0]*STOCK_DIM + \\\r\n",
        "\r\n",
        "            self.state = [ self.previous_state[0]] + \\\r\n",
        "                          self.data.adjcp.values.tolist() + \\\r\n",
        "                          self.previous_state[(STOCK_DIM+1):(STOCK_DIM*2+1)]+ \\\r\n",
        "                          self.data.macd.values.tolist() + \\\r\n",
        "                          self.data.rsi.values.tolist()  + \\\r\n",
        "                          self.data.cci.values.tolist()  + \\\r\n",
        "                          self.data.adx.values.tolist() \r\n",
        "            \r\n",
        "        return self.state\r\n",
        "    \r\n",
        "    def render(self, mode='human',close=False):\r\n",
        "        return self.state\r\n",
        "    \r\n",
        "\r\n",
        "    def _seed(self, seed=None):\r\n",
        "        self.np_random, seed = seeding.np_random(seed)\r\n",
        "        return [seed]"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6uLY4sSjSSE"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from gym.utils import seeding\r\n",
        "import gym\r\n",
        "from gym import spaces\r\n",
        "import matplotlib\r\n",
        "matplotlib.use('Agg')\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pickle\r\n",
        "\r\n",
        "# shares normalization factor\r\n",
        "# 100 shares per trade\r\n",
        "HMAX_NORMALIZE = 100\r\n",
        "# initial amount of money we have in our account\r\n",
        "INITIAL_ACCOUNT_BALANCE=1000000\r\n",
        "# total number of stocks in our portfolio\r\n",
        "STOCK_DIM = 30\r\n",
        "# transaction fee: 1/1000 reasonable percentage\r\n",
        "TRANSACTION_FEE_PERCENT = 0.001\r\n",
        "REWARD_SCALING = 1e-4\r\n",
        "\r\n",
        "class StockEnvTrain(gym.Env):\r\n",
        "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\r\n",
        "    metadata = {'render.modes': ['human']}\r\n",
        "\r\n",
        "    def __init__(self, df,day = 0):\r\n",
        "        #super(StockEnv, self).__init__()\r\n",
        "        #money = 10 , scope = 1\r\n",
        "        self.day = day\r\n",
        "        self.df = df\r\n",
        "\r\n",
        "        # action_space normalization and shape is STOCK_DIM\r\n",
        "        self.action_space = spaces.Box(low = -1, high = 1,shape = (STOCK_DIM,)) \r\n",
        "        # Shape = 181: [Current Balance]+[prices 1-30]+[owned shares 1-30] \r\n",
        "        # +[macd 1-30]+ [rsi 1-30] + [cci 1-30] + [adx 1-30]\r\n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape = (181,))\r\n",
        "        # load data from a pandas dataframe\r\n",
        "        self.data = self.df.loc[self.day,:]\r\n",
        "        self.terminal = False             \r\n",
        "        # initalize state\r\n",
        "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\r\n",
        "                      self.data.adjcp.values.tolist() + \\\r\n",
        "                      [0]*STOCK_DIM + \\\r\n",
        "                      self.data.macd.values.tolist() + \\\r\n",
        "                      self.data.rsi.values.tolist() + \\\r\n",
        "                      self.data.cci.values.tolist() + \\\r\n",
        "                      self.data.adx.values.tolist()\r\n",
        "        # initialize reward\r\n",
        "        self.reward = 0\r\n",
        "        self.cost = 0\r\n",
        "        # memorize all the total balance change\r\n",
        "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\r\n",
        "        self.rewards_memory = []\r\n",
        "        self.trades = 0\r\n",
        "        #self.reset()\r\n",
        "        self._seed()\r\n",
        "\r\n",
        "\r\n",
        "    def _sell_stock(self, index, action):\r\n",
        "        # perform sell action based on the sign of the action\r\n",
        "        if self.state[index+STOCK_DIM+1] > 0:\r\n",
        "            #update balance\r\n",
        "            self.state[0] += \\\r\n",
        "            self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\r\n",
        "             (1- TRANSACTION_FEE_PERCENT)\r\n",
        "\r\n",
        "            self.state[index+STOCK_DIM+1] -= min(abs(action), self.state[index+STOCK_DIM+1])\r\n",
        "            self.cost +=self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\r\n",
        "             TRANSACTION_FEE_PERCENT\r\n",
        "            self.trades+=1\r\n",
        "        else:\r\n",
        "            pass\r\n",
        "\r\n",
        "    \r\n",
        "    def _buy_stock(self, index, action):\r\n",
        "        # perform buy action based on the sign of the action\r\n",
        "        available_amount = self.state[0] // self.state[index+1]\r\n",
        "        # print('available_amount:{}'.format(available_amount))\r\n",
        "\r\n",
        "        #update balance\r\n",
        "        self.state[0] -= self.state[index+1]*min(available_amount, action)* \\\r\n",
        "                          (1+ TRANSACTION_FEE_PERCENT)\r\n",
        "\r\n",
        "        self.state[index+STOCK_DIM+1] += min(available_amount, action)\r\n",
        "\r\n",
        "        self.cost+=self.state[index+1]*min(available_amount, action)* \\\r\n",
        "                          TRANSACTION_FEE_PERCENT\r\n",
        "        self.trades+=1\r\n",
        "        \r\n",
        "    def step(self, actions):\r\n",
        "        # print(self.day)\r\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\r\n",
        "        # print(actions)\r\n",
        "\r\n",
        "        if self.terminal:\r\n",
        "            plt.plot(self.asset_memory,'r')\r\n",
        "            plt.savefig('results/account_value_train.png')\r\n",
        "            plt.close()\r\n",
        "            end_total_asset = self.state[0]+ \\\r\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\r\n",
        "            \r\n",
        "            #print(\"end_total_asset:{}\".format(end_total_asset))\r\n",
        "            df_total_value = pd.DataFrame(self.asset_memory)\r\n",
        "            df_total_value.to_csv('results/account_value_train.csv')\r\n",
        "            #print(\"total_reward:{}\".format(self.state[0]+sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):61]))- INITIAL_ACCOUNT_BALANCE ))\r\n",
        "            #print(\"total_cost: \", self.cost)\r\n",
        "            #print(\"total_trades: \", self.trades)\r\n",
        "            df_total_value.columns = ['account_value']\r\n",
        "            df_total_value['daily_return']=df_total_value.pct_change(1)\r\n",
        "            sharpe = (252**0.5)*df_total_value['daily_return'].mean()/ \\\r\n",
        "                  df_total_value['daily_return'].std()\r\n",
        "            #print(\"Sharpe: \",sharpe)\r\n",
        "            #print(\"=================================\")\r\n",
        "            df_rewards = pd.DataFrame(self.rewards_memory)\r\n",
        "            #df_rewards.to_csv('results/account_rewards_train.csv')\r\n",
        "            \r\n",
        "            # print('total asset: {}'.format(self.state[0]+ sum(np.array(self.state[1:29])*np.array(self.state[29:]))))\r\n",
        "            #with open('obs.pkl', 'wb') as f:  \r\n",
        "            #    pickle.dump(self.state, f)\r\n",
        "            \r\n",
        "            return self.state, self.reward, self.terminal,{}\r\n",
        "\r\n",
        "        else:\r\n",
        "            # print(np.array(self.state[1:29]))\r\n",
        "\r\n",
        "            actions = actions * HMAX_NORMALIZE\r\n",
        "            #actions = (actions.astype(int))\r\n",
        "            \r\n",
        "            begin_total_asset = self.state[0]+ \\\r\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\r\n",
        "            #print(\"begin_total_asset:{}\".format(begin_total_asset))\r\n",
        "            \r\n",
        "            argsort_actions = np.argsort(actions)\r\n",
        "            \r\n",
        "            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\r\n",
        "            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\r\n",
        "\r\n",
        "            for index in sell_index:\r\n",
        "                # print('take sell action'.format(actions[index]))\r\n",
        "                self._sell_stock(index, actions[index])\r\n",
        "\r\n",
        "            for index in buy_index:\r\n",
        "                # print('take buy action: {}'.format(actions[index]))\r\n",
        "                self._buy_stock(index, actions[index])\r\n",
        "\r\n",
        "            self.day += 1\r\n",
        "            self.data = self.df.loc[self.day,:]         \r\n",
        "            #load next state\r\n",
        "            # print(\"stock_shares:{}\".format(self.state[29:]))\r\n",
        "            self.state =  [self.state[0]] + \\\r\n",
        "                    self.data.adjcp.values.tolist() + \\\r\n",
        "                    list(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]) + \\\r\n",
        "                    self.data.macd.values.tolist() + \\\r\n",
        "                    self.data.rsi.values.tolist() + \\\r\n",
        "                    self.data.cci.values.tolist() + \\\r\n",
        "                    self.data.adx.values.tolist()\r\n",
        "            \r\n",
        "            end_total_asset = self.state[0]+ \\\r\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\r\n",
        "            self.asset_memory.append(end_total_asset)\r\n",
        "            #print(\"end_total_asset:{}\".format(end_total_asset))\r\n",
        "            \r\n",
        "            self.reward = end_total_asset - begin_total_asset            \r\n",
        "            # print(\"step_reward:{}\".format(self.reward))\r\n",
        "            self.rewards_memory.append(self.reward)\r\n",
        "            \r\n",
        "            self.reward = self.reward*REWARD_SCALING\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "        return self.state, self.reward, self.terminal, {}\r\n",
        "\r\n",
        "    def reset(self):\r\n",
        "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\r\n",
        "        self.day = 0\r\n",
        "        self.data = self.df.loc[self.day,:]\r\n",
        "        self.cost = 0\r\n",
        "        self.trades = 0\r\n",
        "        self.terminal = False \r\n",
        "        self.rewards_memory = []\r\n",
        "        #initiate state\r\n",
        "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\r\n",
        "                      self.data.adjcp.values.tolist() + \\\r\n",
        "                      [0]*STOCK_DIM + \\\r\n",
        "                      self.data.macd.values.tolist() + \\\r\n",
        "                      self.data.rsi.values.tolist() + \\\r\n",
        "                      self.data.cci.values.tolist() + \\\r\n",
        "                      self.data.adx.values.tolist() \r\n",
        "        # iteration += 1 \r\n",
        "        return self.state\r\n",
        "    \r\n",
        "    def render(self, mode='human'):\r\n",
        "        return self.state\r\n",
        "\r\n",
        "    def _seed(self, seed=None):\r\n",
        "        self.np_random, seed = seeding.np_random(seed)\r\n",
        "        return [seed]\r\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0qnDLgWjYG9"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from gym.utils import seeding\r\n",
        "import gym\r\n",
        "from gym import spaces\r\n",
        "import matplotlib\r\n",
        "matplotlib.use('Agg')\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pickle\r\n",
        "\r\n",
        "# shares normalization factor\r\n",
        "# 100 shares per trade\r\n",
        "HMAX_NORMALIZE = 100\r\n",
        "# initial amount of money we have in our account\r\n",
        "INITIAL_ACCOUNT_BALANCE=1000000\r\n",
        "# total number of stocks in our portfolio\r\n",
        "STOCK_DIM = 30\r\n",
        "# transaction fee: 1/1000 reasonable percentage\r\n",
        "TRANSACTION_FEE_PERCENT = 0.001\r\n",
        "\r\n",
        "# turbulence index: 90-150 reasonable threshold\r\n",
        "#TURBULENCE_THRESHOLD = 140\r\n",
        "REWARD_SCALING = 1e-4\r\n",
        "\r\n",
        "class StockEnvValidation(gym.Env):\r\n",
        "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\r\n",
        "    metadata = {'render.modes': ['human']}\r\n",
        "\r\n",
        "    def __init__(self, df, day = 0, turbulence_threshold=140, iteration=''):\r\n",
        "        #super(StockEnv, self).__init__()\r\n",
        "        #money = 10 , scope = 1\r\n",
        "        self.day = day\r\n",
        "        self.df = df\r\n",
        "        # action_space normalization and shape is STOCK_DIM\r\n",
        "        self.action_space = spaces.Box(low = -1, high = 1,shape = (STOCK_DIM,)) \r\n",
        "        # Shape = 181: [Current Balance]+[prices 1-30]+[owned shares 1-30] \r\n",
        "        # +[macd 1-30]+ [rsi 1-30] + [cci 1-30] + [adx 1-30]\r\n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape = (181,))\r\n",
        "        # load data from a pandas dataframe\r\n",
        "        self.data = self.df.loc[self.day,:]\r\n",
        "        self.terminal = False     \r\n",
        "        self.turbulence_threshold = turbulence_threshold\r\n",
        "        # initalize state\r\n",
        "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\r\n",
        "                      self.data.adjcp.values.tolist() + \\\r\n",
        "                      [0]*STOCK_DIM + \\\r\n",
        "                      self.data.macd.values.tolist() + \\\r\n",
        "                      self.data.rsi.values.tolist() + \\\r\n",
        "                      self.data.cci.values.tolist() + \\\r\n",
        "                      self.data.adx.values.tolist()\r\n",
        "        # initialize reward\r\n",
        "        self.reward = 0\r\n",
        "        self.turbulence = 0\r\n",
        "        self.cost = 0\r\n",
        "        self.trades = 0\r\n",
        "        # memorize all the total balance change\r\n",
        "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\r\n",
        "        self.rewards_memory = []\r\n",
        "        #self.reset()\r\n",
        "        self._seed()\r\n",
        "        \r\n",
        "        self.iteration=iteration\r\n",
        "\r\n",
        "\r\n",
        "    def _sell_stock(self, index, action):\r\n",
        "        # perform sell action based on the sign of the action\r\n",
        "        if self.turbulence<self.turbulence_threshold:\r\n",
        "            if self.state[index+STOCK_DIM+1] > 0:\r\n",
        "                #update balance\r\n",
        "                self.state[0] += \\\r\n",
        "                self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\r\n",
        "                 (1- TRANSACTION_FEE_PERCENT)\r\n",
        "                \r\n",
        "                self.state[index+STOCK_DIM+1] -= min(abs(action), self.state[index+STOCK_DIM+1])\r\n",
        "                self.cost +=self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\r\n",
        "                 TRANSACTION_FEE_PERCENT\r\n",
        "                self.trades+=1\r\n",
        "            else:\r\n",
        "                pass\r\n",
        "        else:\r\n",
        "            # if turbulence goes over threshold, just clear out all positions \r\n",
        "            if self.state[index+STOCK_DIM+1] > 0:\r\n",
        "                #update balance\r\n",
        "                self.state[0] += self.state[index+1]*self.state[index+STOCK_DIM+1]* \\\r\n",
        "                              (1- TRANSACTION_FEE_PERCENT)\r\n",
        "                self.state[index+STOCK_DIM+1] =0\r\n",
        "                self.cost += self.state[index+1]*self.state[index+STOCK_DIM+1]* \\\r\n",
        "                              TRANSACTION_FEE_PERCENT\r\n",
        "                self.trades+=1\r\n",
        "            else:\r\n",
        "                pass\r\n",
        "    \r\n",
        "    def _buy_stock(self, index, action):\r\n",
        "        # perform buy action based on the sign of the action\r\n",
        "        if self.turbulence< self.turbulence_threshold:\r\n",
        "            available_amount = self.state[0] // self.state[index+1]\r\n",
        "            # print('available_amount:{}'.format(available_amount))\r\n",
        "            \r\n",
        "            #update balance\r\n",
        "            self.state[0] -= self.state[index+1]*min(available_amount, action)* \\\r\n",
        "                              (1+ TRANSACTION_FEE_PERCENT)\r\n",
        "\r\n",
        "            self.state[index+STOCK_DIM+1] += min(available_amount, action)\r\n",
        "            \r\n",
        "            self.cost+=self.state[index+1]*min(available_amount, action)* \\\r\n",
        "                              TRANSACTION_FEE_PERCENT\r\n",
        "            self.trades+=1\r\n",
        "        else:\r\n",
        "            # if turbulence goes over threshold, just stop buying\r\n",
        "            pass\r\n",
        "        \r\n",
        "    def step(self, actions):\r\n",
        "        # print(self.day)\r\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\r\n",
        "        # print(actions)\r\n",
        "\r\n",
        "        if self.terminal:\r\n",
        "            plt.plot(self.asset_memory,'r')\r\n",
        "            plt.savefig('results/account_value_validation_{}.png'.format(self.iteration))\r\n",
        "            plt.close()\r\n",
        "            df_total_value = pd.DataFrame(self.asset_memory)\r\n",
        "            df_total_value.to_csv('results/account_value_validation_{}.csv'.format(self.iteration))\r\n",
        "            end_total_asset = self.state[0]+ \\\r\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\r\n",
        "            #print(\"previous_total_asset:{}\".format(self.asset_memory[0]))           \r\n",
        "\r\n",
        "            #print(\"end_total_asset:{}\".format(end_total_asset))\r\n",
        "            #print(\"total_reward:{}\".format(self.state[0]+sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):61]))- self.asset_memory[0] ))\r\n",
        "            #print(\"total_cost: \", self.cost)\r\n",
        "            #print(\"total trades: \", self.trades)\r\n",
        "\r\n",
        "            df_total_value.columns = ['account_value']\r\n",
        "            df_total_value['daily_return']=df_total_value.pct_change(1)\r\n",
        "            sharpe = (4**0.5)*df_total_value['daily_return'].mean()/ \\\r\n",
        "                  df_total_value['daily_return'].std()\r\n",
        "            #print(\"Sharpe: \",sharpe)\r\n",
        "            \r\n",
        "            #df_rewards = pd.DataFrame(self.rewards_memory)\r\n",
        "            #df_rewards.to_csv('results/account_rewards_trade_{}.csv'.format(self.iteration))\r\n",
        "            \r\n",
        "            # print('total asset: {}'.format(self.state[0]+ sum(np.array(self.state[1:29])*np.array(self.state[29:]))))\r\n",
        "            #with open('obs.pkl', 'wb') as f:  \r\n",
        "            #    pickle.dump(self.state, f)\r\n",
        "            \r\n",
        "            return self.state, self.reward, self.terminal,{}\r\n",
        "\r\n",
        "        else:\r\n",
        "            # print(np.array(self.state[1:29]))\r\n",
        "\r\n",
        "            actions = actions * HMAX_NORMALIZE\r\n",
        "            #actions = (actions.astype(int))\r\n",
        "            if self.turbulence>=self.turbulence_threshold:\r\n",
        "                actions=np.array([-HMAX_NORMALIZE]*STOCK_DIM)\r\n",
        "            begin_total_asset = self.state[0]+ \\\r\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\r\n",
        "            #print(\"begin_total_asset:{}\".format(begin_total_asset))\r\n",
        "            \r\n",
        "            argsort_actions = np.argsort(actions)\r\n",
        "            \r\n",
        "            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\r\n",
        "            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\r\n",
        "\r\n",
        "            for index in sell_index:\r\n",
        "                # print('take sell action'.format(actions[index]))\r\n",
        "                self._sell_stock(index, actions[index])\r\n",
        "\r\n",
        "            for index in buy_index:\r\n",
        "                # print('take buy action: {}'.format(actions[index]))\r\n",
        "                self._buy_stock(index, actions[index])\r\n",
        "\r\n",
        "            self.day += 1\r\n",
        "            self.data = self.df.loc[self.day,:]         \r\n",
        "            self.turbulence = self.data['turbulence'].values[0]\r\n",
        "            #print(self.turbulence)\r\n",
        "            #load next state\r\n",
        "            # print(\"stock_shares:{}\".format(self.state[29:]))\r\n",
        "            self.state =  [self.state[0]] + \\\r\n",
        "                    self.data.adjcp.values.tolist() + \\\r\n",
        "                    list(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]) + \\\r\n",
        "                    self.data.macd.values.tolist() + \\\r\n",
        "                    self.data.rsi.values.tolist() + \\\r\n",
        "                    self.data.cci.values.tolist() + \\\r\n",
        "                    self.data.adx.values.tolist()\r\n",
        "            \r\n",
        "            end_total_asset = self.state[0]+ \\\r\n",
        "            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\r\n",
        "            self.asset_memory.append(end_total_asset)\r\n",
        "            #print(\"end_total_asset:{}\".format(end_total_asset))\r\n",
        "            \r\n",
        "            self.reward = end_total_asset - begin_total_asset            \r\n",
        "            # print(\"step_reward:{}\".format(self.reward))\r\n",
        "            self.rewards_memory.append(self.reward)\r\n",
        "            \r\n",
        "            self.reward = self.reward*REWARD_SCALING\r\n",
        "\r\n",
        "        return self.state, self.reward, self.terminal, {}\r\n",
        "\r\n",
        "    def reset(self):  \r\n",
        "        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\r\n",
        "        self.day = 0\r\n",
        "        self.data = self.df.loc[self.day,:]\r\n",
        "        self.turbulence = 0\r\n",
        "        self.cost = 0\r\n",
        "        self.trades = 0\r\n",
        "        self.terminal = False \r\n",
        "        #self.iteration=self.iteration\r\n",
        "        self.rewards_memory = []\r\n",
        "        #initiate state\r\n",
        "        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\r\n",
        "                      self.data.adjcp.values.tolist() + \\\r\n",
        "                      [0]*STOCK_DIM + \\\r\n",
        "                      self.data.macd.values.tolist() + \\\r\n",
        "                      self.data.rsi.values.tolist()  + \\\r\n",
        "                      self.data.cci.values.tolist()  + \\\r\n",
        "                      self.data.adx.values.tolist() \r\n",
        "            \r\n",
        "        return self.state\r\n",
        "    \r\n",
        "    def render(self, mode='human',close=False):\r\n",
        "        return self.state\r\n",
        "    \r\n",
        "\r\n",
        "    def _seed(self, seed=None):\r\n",
        "        self.np_random, seed = seeding.np_random(seed)\r\n",
        "        return [seed]"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGw3O2tHRHDK"
      },
      "source": [
        "def train_A2C(env_train, model_name, timesteps=25000):\r\n",
        "    \"\"\"A2C model\"\"\"\r\n",
        "\r\n",
        "    start = time.time()\r\n",
        "    model = A2C('MlpPolicy', env_train, verbose=0)\r\n",
        "    model.learn(total_timesteps=timesteps)\r\n",
        "    end = time.time()\r\n",
        "\r\n",
        "    model.save(f\"{TRAINED_MODEL_DIR}/{model_name}\")\r\n",
        "    print('Training time (A2C): ', (end - start) / 60, ' minutes')\r\n",
        "    return model\r\n",
        "\r\n",
        "def train_ACER(env_train, model_name, timesteps=25000):\r\n",
        "    start = time.time()\r\n",
        "    model = ACER('MlpPolicy', env_train, verbose=0)\r\n",
        "    model.learn(total_timesteps=timesteps)\r\n",
        "    end = time.time()\r\n",
        "\r\n",
        "    model.save(f\"{TRAINED_MODEL_DIR}/{model_name}\")\r\n",
        "    print('Training time (A2C): ', (end - start) / 60, ' minutes')\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "def train_DDPG(env_train, model_name, timesteps=10000):\r\n",
        "    \"\"\"DDPG model\"\"\"\r\n",
        "\r\n",
        "    # add the noise objects for DDPG\r\n",
        "    n_actions = env_train.action_space.shape[-1]\r\n",
        "    param_noise = None\r\n",
        "    action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\r\n",
        "\r\n",
        "    start = time.time()\r\n",
        "    model = DDPG('MlpPolicy', env_train, param_noise=param_noise, action_noise=action_noise)\r\n",
        "    model.learn(total_timesteps=timesteps)\r\n",
        "    end = time.time()\r\n",
        "\r\n",
        "    model.save(f\"{TRAINED_MODEL_DIR}/{model_name}\")\r\n",
        "    print('Training time (DDPG): ', (end-start)/60,' minutes')\r\n",
        "    return model\r\n",
        "\r\n",
        "def train_PPO(env_train, model_name, timesteps=50000):\r\n",
        "    \"\"\"PPO model\"\"\"\r\n",
        "\r\n",
        "    start = time.time()\r\n",
        "    model = PPO2('MlpPolicy', env_train, ent_coef = 0.005, nminibatches = 8)\r\n",
        "    #model = PPO2('MlpPolicy', env_train, ent_coef = 0.005)\r\n",
        "\r\n",
        "    model.learn(total_timesteps=timesteps)\r\n",
        "    end = time.time()\r\n",
        "\r\n",
        "    model.save(f\"{TRAINED_MODEL_DIR}/{model_name}\")\r\n",
        "    print('Training time (PPO): ', (end - start) / 60, ' minutes')\r\n",
        "    return model\r\n",
        "\r\n",
        "def train_GAIL(env_train, model_name, timesteps=1000):\r\n",
        "    \"\"\"GAIL Model\"\"\"\r\n",
        "    #from stable_baselines.gail import ExportDataset, generate_expert_traj\r\n",
        "    start = time.time()\r\n",
        "    # generate expert trajectories\r\n",
        "    model = SAC('MLpPolicy', env_train, verbose=1)\r\n",
        "    generate_expert_traj(model, 'expert_model_gail', n_timesteps=100, n_episodes=10)\r\n",
        "\r\n",
        "    # Load dataset\r\n",
        "    dataset = ExpertDataset(expert_path='expert_model_gail.npz', traj_limitation=10, verbose=1)\r\n",
        "    model = GAIL('MLpPolicy', env_train, dataset, verbose=1)\r\n",
        "\r\n",
        "    model.learn(total_timesteps=1000)\r\n",
        "    end = time.time()\r\n",
        "\r\n",
        "    model.save(f\"{TRAINED_MODEL_DIR}/{model_name}\")\r\n",
        "    print('Training time (PPO): ', (end - start) / 60, ' minutes')\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "def DRL_prediction(df,\r\n",
        "                   model,\r\n",
        "                   name,\r\n",
        "                   last_state,\r\n",
        "                   iter_num,\r\n",
        "                   unique_trade_date,\r\n",
        "                   rebalance_window,\r\n",
        "                   turbulence_threshold,\r\n",
        "                   initial):\r\n",
        "    ### make a prediction based on trained model###\r\n",
        "\r\n",
        "    ## trading env\r\n",
        "    trade_data = data_split(df, start=unique_trade_date[iter_num - rebalance_window], end=unique_trade_date[iter_num])\r\n",
        "    env_trade = DummyVecEnv([lambda: StockEnvTrade(trade_data,\r\n",
        "                                                   turbulence_threshold=turbulence_threshold,\r\n",
        "                                                   initial=initial,\r\n",
        "                                                   previous_state=last_state,\r\n",
        "                                                   model_name=name,\r\n",
        "                                                   iteration=iter_num)])\r\n",
        "    obs_trade = env_trade.reset()\r\n",
        "\r\n",
        "    for i in range(len(trade_data.index.unique())):\r\n",
        "        action, _states = model.predict(obs_trade)\r\n",
        "        obs_trade, rewards, dones, info = env_trade.step(action)\r\n",
        "        if i == (len(trade_data.index.unique()) - 2):\r\n",
        "            # print(env_test.render())\r\n",
        "            last_state = env_trade.render()\r\n",
        "\r\n",
        "    df_last_state = pd.DataFrame({'last_state': last_state})\r\n",
        "    df_last_state.to_csv('results/last_state_{}_{}.csv'.format(name, i), index=False)\r\n",
        "    return last_state\r\n",
        "\r\n",
        "\r\n",
        "def DRL_validation(model, test_data, test_env, test_obs) -> None:\r\n",
        "    ###validation process###\r\n",
        "    for i in range(len(test_data.index.unique())):\r\n",
        "        action, _states = model.predict(test_obs)\r\n",
        "        test_obs, rewards, dones, info = test_env.step(action)\r\n",
        "\r\n",
        "\r\n",
        "def get_validation_sharpe(iteration):\r\n",
        "    ###Calculate Sharpe ratio based on validation results###\r\n",
        "    df_total_value = pd.read_csv('results/account_value_validation_{}.csv'.format(iteration), index_col=0)\r\n",
        "    df_total_value.columns = ['account_value_train']\r\n",
        "    df_total_value['daily_return'] = df_total_value.pct_change(1)\r\n",
        "    sharpe = (4 ** 0.5) * df_total_value['daily_return'].mean() / \\\r\n",
        "             df_total_value['daily_return'].std()\r\n",
        "    return sharpe\r\n",
        "\r\n",
        "\r\n",
        "def run_ensemble_strategy(df, unique_trade_date, rebalance_window, validation_window) -> None:\r\n",
        "    \"\"\"Ensemble Strategy that combines PPO, A2C and DDPG\"\"\"\r\n",
        "    print(\"============Start Ensemble Strategy============\")\r\n",
        "    # for ensemble model, it's necessary to feed the last state\r\n",
        "    # of the previous model to the current model as the initial state\r\n",
        "    last_state_ensemble = []\r\n",
        "\r\n",
        "    ppo_sharpe_list = []\r\n",
        "    ddpg_sharpe_list = []\r\n",
        "    a2c_sharpe_list = []\r\n",
        "\r\n",
        "    model_use = []\r\n",
        "\r\n",
        "    # based on the analysis of the in-sample data\r\n",
        "    #turbulence_threshold = 140\r\n",
        "    insample_turbulence = df[(df.datadate<20151000) & (df.datadate>=20090000)]\r\n",
        "    insample_turbulence = insample_turbulence.drop_duplicates(subset=['datadate'])\r\n",
        "    insample_turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, .90)\r\n",
        "\r\n",
        "    start = time.time()\r\n",
        "    for i in range(rebalance_window + validation_window, len(unique_trade_date), rebalance_window):\r\n",
        "        print(\"============================================\")\r\n",
        "        ## initial state is empty\r\n",
        "        if i - rebalance_window - validation_window == 0:\r\n",
        "            # inital state\r\n",
        "            initial = True\r\n",
        "        else:\r\n",
        "            # previous state\r\n",
        "            initial = False\r\n",
        "\r\n",
        "        # Tuning trubulence index based on historical data\r\n",
        "        # Turbulence lookback window is one quarter\r\n",
        "        end_date_index = df.index[df[\"datadate\"] == unique_trade_date[i - rebalance_window - validation_window]].to_list()[-1]\r\n",
        "        start_date_index = end_date_index - validation_window*30 + 1\r\n",
        "\r\n",
        "        historical_turbulence = df.iloc[start_date_index:(end_date_index + 1), :]\r\n",
        "        #historical_turbulence = df[(df.datadate<unique_trade_date[i - rebalance_window - validation_window]) & (df.datadate>=(unique_trade_date[i - rebalance_window - validation_window - 63]))]\r\n",
        "\r\n",
        "\r\n",
        "        historical_turbulence = historical_turbulence.drop_duplicates(subset=['datadate'])\r\n",
        "\r\n",
        "        historical_turbulence_mean = np.mean(historical_turbulence.turbulence.values)\r\n",
        "\r\n",
        "        if historical_turbulence_mean > insample_turbulence_threshold:\r\n",
        "            # if the mean of the historical data is greater than the 90% quantile of insample turbulence data\r\n",
        "            # then we assume that the current market is volatile,\r\n",
        "            # therefore we set the 90% quantile of insample turbulence data as the turbulence threshold\r\n",
        "            # meaning the current turbulence can't exceed the 90% quantile of insample turbulence data\r\n",
        "            turbulence_threshold = insample_turbulence_threshold\r\n",
        "        else:\r\n",
        "            # if the mean of the historical data is less than the 90% quantile of insample turbulence data\r\n",
        "            # then we tune up the turbulence_threshold, meaning we lower the risk\r\n",
        "            turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, 1)\r\n",
        "        print(\"turbulence_threshold: \", turbulence_threshold)\r\n",
        "\r\n",
        "        ############## Environment Setup starts ##############\r\n",
        "        ## training env\r\n",
        "        train = data_split(df, start=20090000, end=unique_trade_date[i - rebalance_window - validation_window])\r\n",
        "        env_train = DummyVecEnv([lambda: StockEnvTrain(train)])\r\n",
        "\r\n",
        "        ## validation env\r\n",
        "        validation = data_split(df, start=unique_trade_date[i - rebalance_window - validation_window],\r\n",
        "                                end=unique_trade_date[i - rebalance_window])\r\n",
        "        env_val = DummyVecEnv([lambda: StockEnvValidation(validation,\r\n",
        "                                                          turbulence_threshold=turbulence_threshold,\r\n",
        "                                                          iteration=i)])\r\n",
        "        obs_val = env_val.reset()\r\n",
        "        ############## Environment Setup ends ##############\r\n",
        "\r\n",
        "        ############## Training and Validation starts ##############\r\n",
        "        print(\"======Model training from: \", 20090000, \"to \",\r\n",
        "              unique_trade_date[i - rebalance_window - validation_window])\r\n",
        "        # print(\"training: \",len(data_split(df, start=20090000, end=test.datadate.unique()[i-rebalance_window]) ))\r\n",
        "        # print(\"==============Model Training===========\")\r\n",
        "        print(\"======A2C Training========\")\r\n",
        "        model_a2c = train_A2C(env_train, model_name=\"A2C_30k_dow_{}\".format(i), timesteps=30000)\r\n",
        "        print(\"======A2C Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\r\n",
        "              unique_trade_date[i - rebalance_window])\r\n",
        "        DRL_validation(model=model_a2c, test_data=validation, test_env=env_val, test_obs=obs_val)\r\n",
        "        sharpe_a2c = get_validation_sharpe(i)\r\n",
        "        print(\"A2C Sharpe Ratio: \", sharpe_a2c)\r\n",
        "\r\n",
        "        print(\"======PPO Training========\")\r\n",
        "        model_ppo = train_PPO(env_train, model_name=\"PPO_100k_dow_{}\".format(i), timesteps=100000)\r\n",
        "        print(\"======PPO Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\r\n",
        "              unique_trade_date[i - rebalance_window])\r\n",
        "        DRL_validation(model=model_ppo, test_data=validation, test_env=env_val, test_obs=obs_val)\r\n",
        "        sharpe_ppo = get_validation_sharpe(i)\r\n",
        "        print(\"PPO Sharpe Ratio: \", sharpe_ppo)\r\n",
        "\r\n",
        "        print(\"======DDPG Training========\")\r\n",
        "        model_ddpg = train_DDPG(env_train, model_name=\"DDPG_10k_dow_{}\".format(i), timesteps=10000)\r\n",
        "        #model_ddpg = train_TD3(env_train, model_name=\"DDPG_10k_dow_{}\".format(i), timesteps=20000)\r\n",
        "        print(\"======DDPG Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\r\n",
        "              unique_trade_date[i - rebalance_window])\r\n",
        "        DRL_validation(model=model_ddpg, test_data=validation, test_env=env_val, test_obs=obs_val)\r\n",
        "        sharpe_ddpg = get_validation_sharpe(i)\r\n",
        "\r\n",
        "        ppo_sharpe_list.append(sharpe_ppo)\r\n",
        "        a2c_sharpe_list.append(sharpe_a2c)\r\n",
        "        ddpg_sharpe_list.append(sharpe_ddpg)\r\n",
        "\r\n",
        "        # Model Selection based on sharpe ratio\r\n",
        "        if (sharpe_ppo >= sharpe_a2c) & (sharpe_ppo >= sharpe_ddpg):\r\n",
        "            model_ensemble = model_ppo\r\n",
        "            model_use.append('PPO')\r\n",
        "        elif (sharpe_a2c > sharpe_ppo) & (sharpe_a2c > sharpe_ddpg):\r\n",
        "            model_ensemble = model_a2c\r\n",
        "            model_use.append('A2C')\r\n",
        "        else:\r\n",
        "            model_ensemble = model_ddpg\r\n",
        "            model_use.append('DDPG')\r\n",
        "        ############## Training and Validation ends ##############\r\n",
        "\r\n",
        "        ############## Trading starts ##############\r\n",
        "        print(\"======Trading from: \", unique_trade_date[i - rebalance_window], \"to \", unique_trade_date[i])\r\n",
        "        #print(\"Used Model: \", model_ensemble)\r\n",
        "        last_state_ensemble = DRL_prediction(df=df, model=model_ensemble, name=\"ensemble\",\r\n",
        "                                             last_state=last_state_ensemble, iter_num=i,\r\n",
        "                                             unique_trade_date=unique_trade_date,\r\n",
        "                                             rebalance_window=rebalance_window,\r\n",
        "                                             turbulence_threshold=turbulence_threshold,\r\n",
        "                                             initial=initial)\r\n",
        "        # print(\"============Trading Done============\")\r\n",
        "        ############## Trading ends ##############\r\n",
        "\r\n",
        "    end = time.time()\r\n",
        "    print(\"Ensemble Strategy took: \", (end - start) / 60, \" minutes\")"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxBFnwCdZ0L_",
        "outputId": "7b7897ca-af32-4fc6-8570-b5ae83d3217d"
      },
      "source": [
        "# common library\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import time\r\n",
        "from stable_baselines.common.vec_env import DummyVecEnv\r\n",
        "\r\n",
        "import os\r\n",
        "\r\n",
        "def run_model() -> None:\r\n",
        "    \"\"\"Train the model.\"\"\"\r\n",
        "\r\n",
        "    # read and preprocess data\r\n",
        "    preprocessed_path = \"done_data.csv\"\r\n",
        "    if os.path.exists(preprocessed_path):\r\n",
        "        data = pd.read_csv(preprocessed_path, index_col=0)\r\n",
        "    else:\r\n",
        "        data = preprocess_data()\r\n",
        "        data = add_turbulence(data)\r\n",
        "        data.to_csv(preprocessed_path)\r\n",
        "\r\n",
        "    print(data.head())\r\n",
        "    print(data.size)\r\n",
        "\r\n",
        "    # 2015/10/01 is the date that validation starts\r\n",
        "    # 2016/01/01 is the date that real trading starts\r\n",
        "    # unique_trade_date needs to start from 2015/10/01 for validation purpose\r\n",
        "    unique_trade_date = data[(data.datadate > 20151001)&(data.datadate <= 20200707)].datadate.unique()\r\n",
        "    print(unique_trade_date)\r\n",
        "\r\n",
        "    # rebalance_window is the number of months to retrain the model\r\n",
        "    # validation_window is the number of months to validation the model and select for trading\r\n",
        "    rebalance_window = 63\r\n",
        "    validation_window = 63\r\n",
        "    \r\n",
        "    ## Ensemble Strategy\r\n",
        "    run_ensemble_strategy(df=data, \r\n",
        "                          unique_trade_date= unique_trade_date,\r\n",
        "                          rebalance_window = rebalance_window,\r\n",
        "                          validation_window=validation_window)\r\n",
        "\r\n",
        "    #_logger.info(f\"saving model version: {_version}\")\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    run_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   datadate   tic      adjcp       open  ...    rsi        cci    adx  turbulence\n",
            "0  20090102  AAPL  12.964286  12.268571  ...  100.0  66.666667  100.0         0.0\n",
            "1  20090102   AXP  19.330000  18.570000  ...  100.0  66.666667  100.0         0.0\n",
            "2  20090102    BA  45.250000  42.800000  ...  100.0  66.666667  100.0         0.0\n",
            "3  20090102   CAT  46.910000  44.910000  ...    0.0  66.666667  100.0         0.0\n",
            "4  20090102  CSCO  16.960000  16.410000  ...  100.0  66.666667  100.0         0.0\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "1053360\n",
            "[20151002 20151005 20151006 ... 20200702 20200706 20200707]\n",
            "============Start Ensemble Strategy============\n",
            "============================================\n",
            "turbulence_threshold:  171.0940715631016\n",
            "======Model training from:  20090000 to  20151002\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.5790475130081176  minutes\n",
            "======A2C Validation from:  20151002 to  20160104\n",
            "A2C Sharpe Ratio:  0.011761547580598709\n",
            "======PPO Training========\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:198: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "Training time (PPO):  5.199979094664256  minutes\n",
            "======PPO Validation from:  20151002 to  20160104\n",
            "PPO Sharpe Ratio:  0.0363114667657169\n",
            "======DDPG Training========\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ddpg/policies.py:136: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ddpg/ddpg.py:94: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/ddpg/ddpg.py:444: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:432: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "Training time (DDPG):  0.9539237380027771  minutes\n",
            "======DDPG Validation from:  20151002 to  20160104\n",
            "======Trading from:  20160104 to  20160405\n",
            "previous_total_asset:1000000\n",
            "end_total_asset:1039846.5700802241\n",
            "total_reward:39846.570080224075\n",
            "total_cost:  4506.712610479793\n",
            "total trades:  1438\n",
            "Sharpe:  0.13972312886730306\n",
            "============================================\n",
            "turbulence_threshold:  96.08032158358223\n",
            "======Model training from:  20090000 to  20160104\n",
            "======A2C Training========\n",
            "Training time (A2C):  1.5824512362480163  minutes\n",
            "======A2C Validation from:  20160104 to  20160405\n",
            "A2C Sharpe Ratio:  0.08975495429058986\n",
            "======PPO Training========\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}